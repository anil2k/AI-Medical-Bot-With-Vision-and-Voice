# AI Medical Bot With Vision and Voice
 AI Medical Bot with Vision and Voice offers real-time diagnosis, symptom analysis, and patient interaction using advanced image recognition and speech processing


Built using:
- ğŸ”Š Whisper (via Groq) for voice transcription  
- ğŸ‘ï¸ LLaMA-3 (vision-preview) for image + prompt-based diagnosis  
- ğŸ—£ï¸ Google TTS (or ElevenLabs) for voice output  
- ğŸ›ï¸ Gradio for UI

---

## ğŸš€ Features

- ğŸ¤ Accepts voice input via mic  
- ğŸ–¼ï¸ Accepts medical image (e.g., X-ray, skin, retina)  
- ğŸ§  Returns realistic, concise doctor-like diagnosis (LLM-powered)  
- ğŸ”Š Speaks out the result in human voice  
- âš« Dark-themed Gradio UI

---

## ğŸ—‚ï¸ Project Structure

```
AI-Medical-Bot-With-Vision-and-Voice/
â”œâ”€â”€ app.py                       # Main app logic
â”œâ”€â”€ brain_of_the_doctor.py      # Image encoder + vision LLM analyzer
â”œâ”€â”€ voice_of_the_patient.py     # Audio recording + Whisper transcription
â”œâ”€â”€ voice_of_the_doctor.py      # TTS output using gTTS or ElevenLabs
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Your API keys
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Setup

```bash
# 1. Clone this repo
git clone https://github.com/yourname/AI-Medical-Bot-With-Vision-and-Voice.git
cd AI-Medical-Bot-With-Vision-and-Voice

# 2. Set up virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install required packages
pip install -r requirements.txt

# 4. Add your API keys in a .env file
```

---

## ğŸ” .env Configuration

Create a `.env` file in the project root with:

```env
GROQ_API_KEY=your_groq_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key  # optional
```

> ğŸ“ Note: ElevenLabs is optional if you're using `gTTS`.

---

## â–¶ï¸ How to Run

```bash
python app.py
```

Then open your browser and go to:  
[http://127.0.0.1:7860](http://127.0.0.1:7860)

---

## ğŸ§¾ requirements.txt

```
gradio
gtts
python-dotenv
Pillow
openai
soundfile
torch
torchaudio
```

---

## ğŸ’¡ Prompt Engineering (under the hood)

The system uses the following LLM prompt internally:

> You have to act as a professional doctor...  
> Analyze the image... suggest remedies...  
> Keep the response short (max 2 sentences)...  
> Respond like a real doctor, not an AI.

---

## âš ï¸ Disclaimer

This project is for **educational/demo** use only.  
It is **not a medical device** and should **not be used for real diagnoses**.  
Always consult a real doctor for medical concerns.

---

## ğŸ‘¨â€ğŸ’» Author

Built by [Your Name] â€”  
Pull requests, forks, and suggestions welcome.

---

## ğŸ§  Future Ideas

- Add symptom classifier  
- Enable ElevenLabs streaming output  
- Support video (e.g. ultrasound)  
- Save chat history for follow-ups  

---

